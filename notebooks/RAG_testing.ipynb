{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out creating a Vector database with Chroma and Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"example1\": \"\"\"Here is a synthetic summary of polling data in the UK:\n",
    "\n",
    "Recent opinion polls in the United Kingdom have shown a tight race between the governing Conservative Party and the opposition Labour Party. The latest survey from YouGov has Labour holding a narrow 2-point lead over the Tories among decided voters, with 36% supporting Labour and 34% backing the Conservatives. However, other pollsters like Savanta ComRes have found the two parties running neck-and-neck at 33% each.\n",
    "\n",
    "The smaller Liberal Democrat party is polling in the 12-15% range, while the Green Party and Reform UK are each capturing around 5-7% of the vote in most surveys. There are regional variations, with Labour performing more strongly in urban areas like London, while the Conservatives maintain advantages in many rural constituencies. \n",
    "\n",
    "On key issues, the public appears closely divided on the economy, with pluralities trusting Labour slightly more on cost of living but the Tories ahead on economic management. The Conservatives hold leads on immigration and crime, while Labour is seen as stronger on the NHS and education.\n",
    "\n",
    "Looking ahead to the next general election, expected in 2024 or early 2025, polling averages currently put Labour and the Conservatives in a statistical tie nationally. However, due to the distribution of support, models suggest Labour may have a slight edge in being able to secure a governing majority. Of course, much could still change over the remaining years of this parliament.\"\"\",\n",
    "\"example2\": \"\"\"Here is another synthetic summary of polling data in the UK:\n",
    "\n",
    "The latest opinion polling shows the Conservative Party, led by Prime Minister Rishi Sunak, holding a slender lead over the opposition Labour Party. According to an average compiled by Britain Elects, the Tories are at 34% among decided voters, with Labour trailing just behind at 32%.\n",
    "\n",
    "However, there is significant variation between individual pollsters. A recent Redfield & Wilton survey put the Conservatives up 6 points, while a Survation poll had Labour narrowly ahead by 2%. The leftwing party appears to be benefiting from a squeeze on support for the Liberal Democrats, who are down to around 10%.\n",
    "\n",
    "On the key issue of the economy, voters give the Conservatives only a slight edge in being trusted to handle it best. But Labour has opened up clear leads on priorities like the NHS, education, and the cost-of-living crisis according to many surveys.\n",
    "\n",
    "Looking at leader favorability ratings, both Sunak and Labour's Keir Starmer remain unpopular overall, with roughly 60% viewing each unfavorably. However, Starmer scores better on attributes like competence and vision for the country.\n",
    "\n",
    "If an election were held imminently, the polls suggest a hung parliament is one of the likelier outcomes, with no single party holding a majority. The Conservatives may hold a slight advantage in being able to form a governing coalition with smaller unionist parties.\n",
    "\n",
    "Of course, these are just a snapshot in time and much could change in voting intentions over the remaining years before the next scheduled election in late 2024. The state of the economy will likely be the critical factor driving voters' choices.\"\"\"}\n",
    "\n",
    "for key, value in dict.items():\n",
    "    with open(f\"{key}.txt\", \"w\") as file:\n",
    "        file.write(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"../data/text_summaries/\"\n",
    "\n",
    "# List all files and directories in the specified folder\n",
    "files_and_directories = os.listdir(folder_path)\n",
    "\n",
    "# Filter out only the file paths\n",
    "file_paths = [os.path.join(folder_path, file) for file in files_and_directories if os.path.isfile(os.path.join(folder_path, file))]\n",
    "\n",
    "# Print the file paths\n",
    "for file_path in file_paths:\n",
    "    print(file_path)\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "examples = [file_path]\n",
    "\n",
    "for doc in examples:\n",
    "    raw_documents = TextLoader(doc).load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    documents = text_splitter.split_documents(raw_documents)\n",
    "    print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.llms import (\n",
    "    HuggingFaceHub,\n",
    ")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "import chromadb\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    ),\n",
    "    # persist_directory=\"./chromadb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuned team used this prompt\n",
    "prompt_template = \"\"\"Given a query, return the a summary of the most similar descriptions on the polling descriptions contained in the contect provided.\n",
    " \n",
    "### query: {query}\n",
    "\n",
    " \n",
    "### Context: {context}\n",
    "\n",
    " \n",
    "### Summary:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "    prompt_template\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "chain = (\n",
    "        {\n",
    "        \"context\": itemgetter(\"query\") \n",
    "            | retriever, \n",
    "            #| RunnableLambda(format_docs),\n",
    "        \"query\": itemgetter(\"query\"),\n",
    "    }\n",
    "    | prompt\n",
    "   # | ft_llm\n",
    "   # | StrOutputParser()\n",
    ")\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"What do young men feel about websites\"\n",
    "print(chain.invoke({\"query\": q}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chain.invoke({\"query\": q}).to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#porject specfic\n",
    "import boto3\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "import pandas as pd\n",
    "#local\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "from pathlib import Path\n",
    "class LLMHandler:\n",
    "    \"\"\"LLM handler class - set up client\n",
    "    \"\"\"\n",
    "    def __init__(self, env_path):\n",
    "        load_dotenv(env_path)\n",
    "        boto3.setup_default_session(aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "                            aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "                           aws_session_token = os.getenv('AWS_SESSION_TOKEN'))\n",
    "        client = boto3.client(service_name='bedrock-runtime',\n",
    "                       region_name=os.getenv('AWS_DEFAULT_REGION'))\n",
    "        self.llm = BedrockChat(model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "              client = client,\n",
    "             )\n",
    "        self.problem_cases = {}\n",
    "    def get_data(self,\n",
    "                 prompt,\n",
    "                 data) -> pd.DataFrame:\n",
    "        \"\"\"summarise input speech data\n",
    "        Args:\n",
    "            prompt (langchain PromptTemplate): prompt to be passed to LLM\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        output = pd.DataFrame()\n",
    "        chain = prompt | self.llm\n",
    "        response = chain.invoke({\"prompt\":prompt,\n",
    "                                \"data\": data})\n",
    "        return response\n",
    "#%%\n",
    "#---- prompt\n",
    "prompt = PromptTemplate(\n",
    "    # template = \"\"\"\n",
    "    # \\n\\nHuman: You are a super helpful robot that does exactly as told.\n",
    "    # Outline the purpose of this poll and briefly describe the data.\n",
    "    # Include where the poll came from, the question number, and a description of the CSV file.\n",
    "    # Do not exceed more than 200 words.\n",
    "    # write the poll name, the table number, the question and a summary of the data\n",
    "    # {data}\n",
    "    # Do not repeat instructions back to me, just complete the task.\n",
    "    #  \\n\\nAssistant:\"\"\",\n",
    "    template = \"\"\"\n",
    "    \\n\\nHuman: You are a super helpful robot that does exactly as told.\n",
    "    For each question in this poll, outline the purpose of the question and briefly describe the outcomes of the poll.\n",
    "    Include where the question came from, the question number, and a description of the CSV file.\n",
    "    Do not exceed more than 200 words.\n",
    "    seperate repsonses for each question with a ---\n",
    "    write the poll name, the table number, the question and a summary of the data\n",
    "    {data}\n",
    "    Do not repeat instructions back to me, or return anything else just complete the task.\n",
    "     \\n\\nAssistant:\"\"\",\n",
    "    input_variables=[\"data\"])\n",
    "## --------------- set up CFG adn LLM\n",
    "base_dir = Path(os.getcwd()).parents[0]\n",
    "data_dir = base_dir /'data'\n",
    "example_data_path = data_dir / 'savanta_data'\n",
    "poll_files = [x for x in os.listdir(example_data_path) if '.csv' in x]\n",
    "#%%\n",
    "handler = LLMHandler(env_path =base_dir/ '.env')\n",
    "for file in poll_files[0:1]:\n",
    "    data = pd.read_csv(example_data_path /file)\n",
    "    response = handler.get_data(prompt=prompt,\n",
    "                        data = data.to_csv())\n",
    "#%%\n",
    "# with open(f\"{file}.txt\", \"w\") as file:\n",
    "#     file.write(response.dict()['content'])\n",
    "# data_path = data_dir/'savanta_data/Omni_W184_HomelessAndPolicePR_tables_Private.xlsx'\n",
    "# sheets = parse_santava_excel(data_path)\n",
    "# poll_data = ''\n",
    "# for s in sheets:\n",
    "#     poll_data = ''.join([poll_data, s.to_csv()])\n",
    "# response = handler.get_data(prompt=prompt,\n",
    "#                         data = poll_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
